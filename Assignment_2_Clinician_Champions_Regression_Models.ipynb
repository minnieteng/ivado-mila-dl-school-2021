{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_Clinician Champions_Regression Models",
      "provenance": [],
      "collapsed_sections": [
        "FyHyieO_0kbZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minnieteng/ivado-mila-dl-school-2021/blob/main/Assignment_2_Clinician_Champions_Regression_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyHyieO_0kbZ"
      },
      "source": [
        "## Welcome to this Michener Institute & Vector Institute Course!\n",
        "\n",
        "This is an optional Python tutorial in the ‘AI for Clinician Champions Certificate' program!  https://michener.ca/ce_course/ai-for-clinician-champions-certificate-program/ - \n",
        "This program is offered by Michener Institute & Vector Institute for clinicians who wish to learn more about AI in Healthcare.\n",
        "\n",
        "Instructor: Dr. Devin Singh (@DrDevSK) | Assignment Developer: Alex Yun | Course Tutors: Jianan Chen, Flora Wan, and Alex Yun | Course Director: Shingai Manjengwa (@Tjido) \n",
        " \n",
        "***Never stop learning!***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDnytPhDEOPL"
      },
      "source": [
        "# Case Study 1 - Regression Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEI06dUaQDLI"
      },
      "source": [
        "We will be exploring an medical cost dataset with various demographic and health information on patients. We can tackle 2 main ideas in supervised learning: (1) regression and (2) classification.\n",
        "\n",
        "For a regression task, the goal is to predict medical costs using a linear regression model. For a (binary) classification task, the goal is to predict if the insurance beneficiary is a smoker or a non-smoker with a logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpqdZKw8y3c3"
      },
      "source": [
        "# Quick recap of Python syntax:\n",
        "# the '#' sign denotes comments in the code - read all comments as they may include instructions for you to run in the code\n",
        "# click on the 'play' button on the left hand side of the code to run each code block\n",
        "# let's run some models!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQoAlMkQEWbN"
      },
      "source": [
        "# Import relevant Python packages\n",
        "import matplotlib.pyplot as plt        # visualization\n",
        "import numpy as np                     # matrices and high-level math functions\n",
        "import pandas as pd                    # data manipulation\n",
        "import seaborn as sns                  # visualization (based on matplotlib)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "from scipy import stats                # scientific computing\n",
        "# sklearn is a popular machine learning library\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from yellowbrick.cluster import KElbowVisualizer # visualize optimal number of clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoeLaZUEdcy"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pno_PrCvEgHo"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/salexyun/Michener-AI-for-Clinician-Champions/main/medical_cost.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# ***you try*** by uncommenting the following line, 'df.head()', you can view the first few lines of data in the data file\n",
        "# you may specify the number of lines to reveal in the preview of your data set e.g., df.head(20)\n",
        "# df.head() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yefs4kYfzmLf"
      },
      "source": [
        "# run the code to view the data here \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhvxKLavTDTW"
      },
      "source": [
        "We have just read a comma-separated values (csv) file into a pandas data structure called DataFrame. This allows us to input the case study data into this programming environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qeh9WDWia5SE"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWmHgwdfbB6v"
      },
      "source": [
        "print(\"Dimensionality of the DataFrame:\", df.shape)\n",
        "df.describe()\n",
        "print(\"Data type of each feature:\")\n",
        "df.dtypes\n",
        "print(\"\\nAre there any missing datapoints in the dataset?\", df.isnull().values.any())\n",
        "print(\"Number of duplicated rows:\", df.duplicated().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvZ8bTJyx4Gp"
      },
      "source": [
        "There are 1338 individual datapoints with 7 columns or features in the dataset:\n",
        "- age: age of the primary beneficiary\n",
        "  - ratio (continuous variable)\n",
        "- sex: sex of the beneficiary (male or female)\n",
        "  - nominal (categorical variable)\n",
        "- bmi: body mass index; a value derived from the mass and height of the beneficiary\n",
        "  - interval (continuous variable)\n",
        "- children: number of children covered by the insurance\n",
        "  - ratio (discrete variable)\n",
        "- smoker: whether the beneficiary smokes or not (yes or no)\n",
        "  - nominal (categorical variable)\n",
        "- region: residential area of the beneficiary in the U.S.\n",
        "  - nominal (categorical variable)\n",
        "- charges: individual medical costs billed by the insurance\n",
        "  - ratio (continuous variable)\n",
        "\n",
        "**int64** refers to integer numbers; **float64** refers to floating point numbers; and **object** refers to texts or alphanumeric values.\n",
        "\n",
        "Luckily there are no missing datapoints in the dataset. Missing data can be problematic when carrying out data analysis. To combat this, we can either drop the entire row or use data imputation strategies where the missing value is replaced by a substituted value.\n",
        "\n",
        "There is one duplicated row and will be removed accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlwSE7SDH6ka"
      },
      "source": [
        "df.drop_duplicates(keep='first', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yea-iAs-bWId"
      },
      "source": [
        "### Data visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPCR8tGgZf7h"
      },
      "source": [
        "In addition to the descriptive statistics, visualizing the distribution of the data can provide additional information on the data itself and can guide us how to carry out the analysis appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84mw9s36bTcu",
        "collapsed": true
      },
      "source": [
        "sns.histplot(df['charges'], kde=True)\n",
        "print(stats.shapiro(df['charges']));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9WQWxtbbl2"
      },
      "source": [
        "The distribution appears to be non-Gaussian and positively skewed (or right skewed). We can formally test the normality with the Shapiro–Wilk test and can confirm that the distribution is indeed not normal.\n",
        "\n",
        "***Note, normality is a condition for regression models.\n",
        "\n",
        "While it is not always necessary to transform data, it often helps with interpretability and to meet certain assumptions for statistical inference. In our case, we will be using the Box-Cox transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6f-O7I9bcv9"
      },
      "source": [
        "charges_transformed = stats.boxcox(df['charges'])[0]\n",
        "sns.histplot(charges_transformed, kde=True);\n",
        "plt.xlabel('charges (transformed)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-rF2TXa2qHf"
      },
      "source": [
        "One of the major assumptions of linear regression is that there should be little to no multicollinearity; that is, independnet variables should be relatively independent from one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIpAYu_obhyZ"
      },
      "source": [
        "sns.heatmap(df.corr(), cmap='Blues', annot=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHUtckPTbkjS"
      },
      "source": [
        "Checking the correlations between variables, we can ensure that the independent variables are indeed independent from one another.\n",
        "\n",
        "***Independence of variables is a condition for regression.\n",
        "\n",
        "We can now move on to visualizing the independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxe1PGGkbobn"
      },
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(20,5))\n",
        "sns.histplot(x=df['age'], kde=True, ax=ax0);\n",
        "sns.histplot(x=df['bmi'], kde=True, ax=ax1);\n",
        "sns.countplot(x=df['children'], ax=ax2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uYygOKBb-oh"
      },
      "source": [
        "Using prior knowledge, we may be able to come up with a few hypotheses. In particular, older individuals and/or individuals with higher BMI would likely to have more ailments, and thus may incur higher medical costs.\n",
        "\n",
        "***Correlation is different from causation. We are not establishing causal relationships between variables. \n",
        "\n",
        "While BMI is a continuous variable, it is often described as a (ordinal) categorical variable with the following categories: (1) underweight; (2) normal weight; (3) overweight; and (4) obese. As such, we can create a new feature accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G09EZjA7iW5",
        "collapsed": true
      },
      "source": [
        "conditions = [(df['bmi'] < 18.5),\n",
        "              (df['bmi'] >= 18.5) & (df['bmi'] < 25),\n",
        "              (df['bmi'] >= 25) & (df['bmi'] < 30),\n",
        "              (df['bmi'] >= 30)]\n",
        "labels = ['underweight', 'normal weight', 'overweight', 'obese']\n",
        "df['bmi_categories'] = np.select(conditions, labels)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TfTzUbGcGu5",
        "collapsed": true
      },
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(20,5))\n",
        "sns.lineplot(x='age', y='charges', data=df, ax=ax0);\n",
        "sns.barplot(x='bmi_categories', y='charges', data=df,\n",
        "            order=['underweight', 'normal weight', 'overweight', 'obese'], ax=ax1);\n",
        "sns.barplot(x='children', y='charges', data=df, ax=ax2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtS2C5wDcF-W"
      },
      "source": [
        "As we suspected, medical cost tends to increase as a function of age or bmi. On the other hand, it is difficult to draw any conclusion regarding the medical costs based on the number of children/dependents that the beneficiary has. Let us examine rest of the independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVinUItopXIr",
        "collapsed": true
      },
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(20,5))\n",
        "sns.countplot(data=df, x='sex', ax=ax0);\n",
        "sns.countplot(data=df, x='smoker', ax=ax1);\n",
        "sns.countplot(data=df, x='region', ax=ax2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6DMoCdw6wmF"
      },
      "source": [
        "*N.b.*, the number of smokers vs. non-smokers is quite unbalanced and it may or may not cause bias when training the model. This can be potentially addressed by data augmentation techniques. We will ignore this for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri_JDehGoYOi",
        "collapsed": true
      },
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(20,5))\n",
        "sns.pointplot(x='sex', y='charges', data=df, ax=ax0);\n",
        "sns.pointplot(x='smoker', y='charges', data=df, ax=ax1);\n",
        "sns.pointplot(x='region', y='charges', data=df, ax=ax2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sIwn3OQcRTi"
      },
      "source": [
        "Initial thoughts on above plots:\n",
        "- It appears that there may be sex differences in the medical costs; in particular, male, on average, spends more on medical procedures.\n",
        "- Not surprisingly, medical costs are likely to be higher for smokers, compared to non-smokers.\n",
        "- Interestingly, where one lives seems to have an effect on the medical costs. Most likely due to the differences in the state law, healthcare policies, and lifestyle of individuals living in different regions within the U.S."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFgMkKSVVnI"
      },
      "source": [
        "### Aggregate plots and clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Wq3xT3UFix"
      },
      "source": [
        "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15,5))\n",
        "sns.boxplot(x='smoker', y='charges', hue='sex', data=df, ax=ax0);\n",
        "sns.boxplot(x='smoker', y='charges', hue='bmi_categories', hue_order=labels, data=df, ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftnV2w9kPeuo"
      },
      "source": [
        "## Unsupervised Learning: Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qd7tt7Ml0OY"
      },
      "source": [
        "partial_df = df[[\"bmi\", \"charges\"]]\n",
        "\n",
        "# Instantiate the clustering model and visualizer\n",
        "visualizer = KElbowVisualizer(KMeans(), k=(2,5))\n",
        "visualizer.fit(partial_df) # fit the data to the visualizer\n",
        "visualizer.poof()          # finalize and render the figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S58dLS6QsMhn"
      },
      "source": [
        "From looking at the visualizer, we can conclude that the optimal number of clusters is 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Xovl84sMIi"
      },
      "source": [
        "kmeans = KMeans(n_clusters=3) # initialize K-Means with 3 clusters\n",
        "kmeans.fit(partial_df)\n",
        "print(kmeans.labels_)\n",
        "print(kmeans.cluster_centers_)\n",
        "\n",
        "# Visualize the clusters\n",
        "sns.scatterplot(x=partial_df.values[:,0], y=partial_df.values[:,1], c=kmeans.labels_, cmap='Accent', s=30).set(title='Clusters Observed by the K-Means Clustering');\n",
        "sns.scatterplot(x=kmeans.cluster_centers_[:,0], y=kmeans.cluster_centers_[:,1], color='black', marker='x', s=300);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QivJ02_uu8K"
      },
      "source": [
        "### Addendum: aggregate plots\n",
        "We could have visualized additional clusters by manual plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8I-fTEfleLV"
      },
      "source": [
        "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20,5))\n",
        "sns.scatterplot(x='bmi', y='charges', hue='bmi_categories', data=df, ax=ax0);\n",
        "sns.scatterplot(x='bmi', y='charges', hue='smoker', data=df, ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diasflAiAgeb"
      },
      "source": [
        "sns.scatterplot(x='bmi', y='charges', hue='smoker', data=df).set(title='Charges as a function of bmi, grouped by smoking status');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4VeimPLcRzz"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFv-p30XcUUB"
      },
      "source": [
        "Given that we wish to use a regression model and some of the features are non-numeric, we must transform them via feature encoding. There are several encoding strategies and can vary depending on the nature of the feature (i.e., nominal vs. ordinal). In our case, we will be using a simple label encoder that turns the target labels with the value between 0 and n_classes-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8OC8wGcXEv",
        "collapsed": true
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "df['sex_encoded'] = encoder.fit_transform(df['sex'])\n",
        "df['smoker_encoded'] = encoder.fit_transform(df['smoker'])\n",
        "df['region_encoded'] = encoder.fit_transform(df['region'])\n",
        "df['charges_transformed'] = stats.boxcox(df['charges'])[0]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji8FVgGGcaRr"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf_FuqD0XbxJ"
      },
      "source": [
        "We have more or less completed the heavy lifting already. Contrary to popular belief, most of data science and AI (machine learning) is about exploring data and feature engineering (i.e., cleaning up data). That said, we are ready to define the model, train the model, make predictions, and evaluate the performance of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvveSw2cmPFt"
      },
      "source": [
        "### Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_adtPdZcb2_"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqmivzNAcdjV",
        "collapsed": true
      },
      "source": [
        "# Dropping features that will not be used in the model\n",
        "X = df.drop(['sex', 'smoker', 'region', 'charges', 'bmi_categories', 'charges_transformed'], axis=1)\n",
        "y = df['charges_transformed']\n",
        "X.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0) # 90-10 split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWJXxU3gZFQ0"
      },
      "source": [
        "We will split the dataset into different datasets: (1) training set; and (2) test set. When we develop a model, we train the model using the samples in the training set. Once the model has learned, we evaluate the performance of our model with the samples in the test set. By testing on unseen data, we minimize the bias of our model and can accurately estimate the generalizability and predictive power of our model. Here, we have split the dataset into 90% training set and 10% test set. A typical split includes 70-30 split, 80-20 split, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KuyVu2Gcd0Y",
        "collapsed": true
      },
      "source": [
        "linear_model = LinearRegression() # define the model\n",
        "linear_model.fit(X_train, y_train) # fit our data into the model and train it\n",
        "\n",
        "print(linear_model.intercept_)\n",
        "print(linear_model.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqffrohFcjHK"
      },
      "source": [
        "#### Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auWuuZb2cuPK"
      },
      "source": [
        "We will now make predictions on data (test set) that was not part of the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYYwiEKpclCj"
      },
      "source": [
        "y_pred = linear_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-EMHFI2coUj"
      },
      "source": [
        "#### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNxRBmTOc5UL"
      },
      "source": [
        "Mean Squared Error $(MSE) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
        "\n",
        "Mean Absolute Error $(MAE) = \\frac{1}{n} \\sum_{i=1}^{n} \\lvert y_i - \\hat{y_i} \\rvert$\n",
        "\n",
        "Both MSE and MAE represent the difference between the actual values and predicted values. Lower value indicates a better fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXFpEXB8dodQ"
      },
      "source": [
        "$R^2 = 1 - \\frac{RSS}{TSS}$, where\n",
        "\n",
        "$RSS=\\sum_i (y_i - \\hat{y})^2=$ sum of squares of residuals\n",
        "\n",
        "$TSS=\\sum_i (y_i - \\bar{y})^2=$ total sum of squares\n",
        "\n",
        "The coefficient of determination ($R^2$) is a measure of how well the model fits the dependent variable. The value ranges from 0 to 1; higher value indicating a better fit. R Squared may also be expressed as a percentage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruywwf7ucqui"
      },
      "source": [
        "print(\"Mean squared error (MSE) =\", metrics.mean_squared_error(y_test, y_pred))\n",
        "# print(\"Root Mean squared error (RMSE) =\", metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
        "print(\"Mean absolute error (MAE) =\", metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"R^2 =\", metrics.r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G2TbAl-FGjI"
      },
      "source": [
        "Our model performs quite well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMJKyKB8Gt77"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x91DtaI0Gw6i"
      },
      "source": [
        "Moving on to the classification problem; we will try to predict if the insurance beneficiary is a smoker or a non-smoker with a logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvcxq0FnmanH"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3b42_5bmOX",
        "collapsed": true
      },
      "source": [
        "X = df[['age', 'bmi', 'children', 'sex_encoded', 'region_encoded', 'charges_transformed']]\n",
        "y = df['smoker_encoded']\n",
        "X.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "logit_model = LogisticRegression()\n",
        "logit_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXb2X2E8me5_"
      },
      "source": [
        "#### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk5Y-g8YmgoU"
      },
      "source": [
        "y_pred = logit_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLOUC1cUmh7p"
      },
      "source": [
        "#### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLdVyM0-mtaZ"
      },
      "source": [
        "For a classification task, it is often useful to visualize using the confusion matrix. Recall in confusion matrix:\n",
        "\n",
        "|                    |Actual/true class    | (observation)       |\n",
        "|--------------------|--------------------:|:--------------------|\n",
        "|**Predicted class** | true positive (tp)  | false positive (fp) |\n",
        "|**(expectation)**   | false negative (fn) | true negative (tn)  | \n",
        "\n",
        "- tp: correct result\n",
        "- fp: unexpected result (type I error)\n",
        "- fn: missing result (type II error)\n",
        "- tn: correct absence of result\n",
        "\n",
        "We can utilize several metrics including precision, recall, and $F$ measure:\n",
        "$$\\text{precision} = \\frac{tp}{tp + fp}$$\n",
        "$$\\text{recall} = \\frac{tp}{tp + fn}$$\n",
        "$$F_1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er93dF-9e7VX",
        "collapsed": true
      },
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=logit_model.classes_)\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logit_model.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show();\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=['non-smoker', 'smoker']));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3MUsaqEvlaX"
      },
      "source": [
        "Again, our model performs very well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8iPofPw1vb0"
      },
      "source": [
        "### Assignment Notes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Suppose you are dealing with the hospital auditor whose main goal is to reduce hospital costs; based on this data analysis, the auditor suggests that your hospital should have a capacity limit on patients with high BMI as they are likely to incur more medical costs. \n",
        "*   Based on the data analysis, is this a fair assessment? Do you trust this data set? Do you trust this model? Using the data analysis and what you are learning in this course, how would you respond to the auditor?\n",
        "*   While working with a data scientist, you concluded that BMI is a useful feature in predicting medical costs, as well as certain patient outcomes. What reservations do you have about using this feature in a model? Are you creating bias unknowingly?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znCg6b8t04o6"
      },
      "source": [
        "Congratulations, you have completed an optional Python tutorial in the ‘AI for Clinician Champions Certificate' program!  \n",
        "https://michener.ca/ce_course/ai-for-clinician-champions-certificate-program/\n",
        "\n",
        "This program is offered by Michener Institute & Vector Institute for clinicians who wish to learn more about AI in Healthcare.\n",
        "\n",
        "Instructor: Dr. Devin Singh (@DrDevSK) | Assignment Developer: Alex Yun | Course Tutors: Jianan Chen, Flora Wan, and Alex Yun | Course Director: Shingai Manjengwa (@Tjido) \n",
        "\n",
        "***Never stop learning!***\n"
      ]
    }
  ]
}